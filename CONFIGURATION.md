# üìñ Guide de Configuration

Ce document d√©crit tous les param√®tres configurables de l'application d'analyse de documents IT.

## üîß Variables d'Environnement

Cr√©ez un fichier `.env` √† la racine du projet avec les variables suivantes :

### Obligatoires

```bash
# Configuration Azure OpenAI
AZURE_API_KEY="votre_cle_api"
AZURE_API_BASE="https://votre-instance.openai.azure.com"
AZURE_API_VERSION="2024-02-01"
```

### Optionnelles

```bash
# Mod√®les utilis√©s (par d√©faut)
MODEL_NAME="azure/gpt-4.1-mini"                     # Mod√®le de g√©n√©ration
EMBEDDING_MODEL_NAME="azure/text-embedding-3-small" # Mod√®le d'embeddings

# Limites de s√©curit√©
MAX_FILE_SIZE_BYTES=52428800                        # Taille max fichier (50 MB)
MAX_INPUT_TOKENS=100000                             # Limite tokens en entr√©e

# Logging
LITELLM_LOG="ERROR"                                 # Niveau de log : DEBUG, INFO, WARNING, ERROR
```

## ‚öôÔ∏è Param√®tres de Performance

### Retry Logic

Configur√© dans `config.py` :

```python
MAX_RETRIES = 3              # Nombre de tentatives en cas d'√©chec
RETRY_BASE_DELAY = 2         # D√©lai initial (secondes)
RETRY_MAX_DELAY = 16         # D√©lai maximum (secondes)
```

**Comportement** : En cas d'√©chec API, le syst√®me retente avec un d√©lai exponentiel :
- Tentative 1 : imm√©diate
- Tentative 2 : apr√®s 2s
- Tentative 3 : apr√®s 4s
- √âchec final : apr√®s 8s

### Rate Limiting

```python
NB_WORKERS = 4               # Nombre de workers parall√®les pour embeddings
BATCH_SIZE = 10              # Taille des lots d'embeddings
RATE_LIMIT_DELAY = 0.1       # D√©lai entre requ√™tes (secondes)
```

**Recommandations** :
- **Azure Tier Standard** : `NB_WORKERS=4`, `RATE_LIMIT_DELAY=0.1`
- **Azure Tier Premium** : `NB_WORKERS=8`, `RATE_LIMIT_DELAY=0.05`
- **En cas de rate limit** : R√©duire `NB_WORKERS` ou augmenter `RATE_LIMIT_DELAY`

## üéØ Param√®tres RAG (rag_analysis.py)

### Chunking

Configurables via l'interface Streamlit (sidebar) :

| Param√®tre | D√©faut | Plage | Description |
|-----------|--------|-------|-------------|
| **Taille des segments** | 600 tokens | 200-1500 | Taille cible d'un chunk |
| **Overlap** | 120 tokens | 0-400 | Contexte partag√© entre chunks |

**Impact** :
- ‚¨ÜÔ∏è **Taille segments** : Moins de chunks, contexte plus complet, mais moins pr√©cis
- ‚¨áÔ∏è **Taille segments** : Plus de chunks, recherche plus fine, mais perte de contexte
- ‚¨ÜÔ∏è **Overlap** : Meilleure continuit√©, mais redondance et co√ªt accru
- ‚¨áÔ∏è **Overlap** : Moins de redondance, mais risque de perte d'information

**Recommandations par cas d'usage** :

| Type de documents | Taille segment | Overlap |
|-------------------|----------------|---------|
| **Documents techniques** (specs, code) | 400-500 | 80-100 |
| **Documents financiers** (budgets, contrats) | 600-800 | 120-150 |
| **Documents mixtes** (RPO, PTC) | 500-700 | 100-150 |
| **Documents longs** (> 50 pages) | 800-1000 | 150-200 |

### Retrieval

| Param√®tre | D√©faut | Plage | Description |
|-----------|--------|-------|-------------|
| **Top-K** | 6 | 3-20 | Nombre de chunks utilis√©s pour la g√©n√©ration |
| **Seuil similarit√©** | 0.15 | 0.0-1.0 | Score minimum de pertinence |
| **MMR activ√©** | ‚úÖ Oui | - | Diversification des r√©sultats |
| **MMR Lambda (Œª)** | 0.7 | 0.1-0.9 | Balance pertinence/diversit√© |

**Impact MMR Lambda** :
- **Œª = 0.9** : Favorise la pertinence (r√©sultats similaires)
- **Œª = 0.5** : Balance √©quilibr√©e
- **Œª = 0.1** : Favorise la diversit√© (r√©sultats vari√©s)

**Recommandations** :

| Objectif | Top-K | Seuil | MMR | Lambda |
|----------|-------|-------|-----|--------|
| **Synth√®se globale** | 8-12 | 0.10 | ‚úÖ | 0.5-0.6 |
| **Recherche pr√©cise** | 3-5 | 0.25 | ‚ùå | - |
| **Analyse exhaustive** | 15-20 | 0.05 | ‚úÖ | 0.7 |
| **Documents courts** | 3-6 | 0.20 | ‚ùå | - |

## üõ°Ô∏è S√©curit√©

### Validation des Chemins

L'application bloque automatiquement l'acc√®s √† :
- `/etc/`, `/sys/`, `/proc/`, `/root/` (Linux)
- `C:\Windows\`, `C:\Program Files\` (Windows)
- Fichiers sensibles : `.ssh`, `.aws`, `credentials`

**Configuration** : Modifiez `FORBIDDEN_PATH_PATTERNS` dans `config.py`

### Taille des Fichiers

Par d√©faut : **50 MB maximum par fichier**

Pour modifier :
```bash
# .env
MAX_FILE_SIZE_BYTES=104857600  # 100 MB
```

### Extensions Autoris√©es

Par d√©faut : `.pdf`, `.docx`, `.txt`

Pour modifier dans `config.py` :
```python
ALLOWED_EXTENSIONS = {".pdf", ".docx", ".txt", ".md"}
```

## üí∞ Estimation des Co√ªts

### Mod√®le par D√©faut (gpt-4.1-mini)

| Sc√©nario | Input Tokens | Output Tokens | Co√ªt (USD) |
|----------|--------------|---------------|------------|
| **5 documents** | ~30,000 | ~800 | $0.05 |
| **10 documents** | ~60,000 | ~1,500 | $0.10 |
| **20 documents** | ~120,000 | ~2,500 | $0.20 |

**Embeddings** (text-embedding-3-small) :
- ~50 documents √ó 5 chunks = 250 embeddings
- Co√ªt : ~$0.0001 (n√©gligeable)

### Optimisation des Co√ªts

1. **R√©duire Top-K** : Moins de chunks = moins de tokens
2. **Augmenter seuil similarit√©** : Filtre plus strict
3. **Utiliser le cache** : √âvite de recalculer les embeddings
4. **Chunk size optimal** : 600-800 tokens (bon compromis)

## üöÄ Modes d'Utilisation Recommand√©s

### Mode D√©veloppement

```bash
# .env
LITELLM_LOG="DEBUG"
MAX_FILE_SIZE_BYTES=10485760  # 10 MB
NB_WORKERS=2
```

### Mode Production

```bash
# .env
LITELLM_LOG="ERROR"
MAX_FILE_SIZE_BYTES=52428800  # 50 MB
NB_WORKERS=4
```

### Mode Haute Performance

```bash
# .env
LITELLM_LOG="WARNING"
NB_WORKERS=8
BATCH_SIZE=15
RATE_LIMIT_DELAY=0.05
```

**Sidebar RAG** :
- Taille segment : 800
- Overlap : 150
- Top-K : 10
- MMR activ√© : Oui (Œª=0.6)

## üß™ Tests

Lancer les tests unitaires :

```bash
# Installer pytest
pip install pytest pytest-mock

# Lancer tous les tests
pytest test_utils.py -v

# Lancer un test sp√©cifique
pytest test_utils.py::TestValidation::test_validate_file_path_valid -v

# Avec couverture de code
pip install pytest-cov
pytest test_utils.py --cov=utils --cov-report=html
```

## üìù Logs

### Configuration des Logs

Les logs sont √©crits dans la sortie standard avec le format :
```
2026-01-14 10:30:15 - utils - INFO - Chemin valid√© : /home/user/documents
```

### Niveaux de Log

- **DEBUG** : Tous les d√©tails (d√©veloppement uniquement)
- **INFO** : √âv√©nements normaux (scan, validation, API calls)
- **WARNING** : Avertissements (fichiers ignor√©s, fallbacks)
- **ERROR** : Erreurs critiques (√©checs API, validation)

### Filtrer les Logs

```bash
# Voir uniquement les erreurs
streamlit run app.py 2>&1 | grep ERROR

# Sauvegarder les logs
streamlit run app.py 2>&1 | tee app.log
```

## üîç Troubleshooting

### Erreur "Rate Limit Exceeded"

**Solution** : R√©duire `NB_WORKERS` dans `config.py` :
```python
NB_WORKERS = 2  # Au lieu de 4
```

### Erreur "Token Limit Exceeded"

**Solution** : R√©duire `MAX_INPUT_TOKENS` ou `Top-K` :
```python
MAX_INPUT_TOKENS = 50000  # Au lieu de 100000
```

### Erreur "File Too Large"

**Solution** : Augmenter `MAX_FILE_SIZE_BYTES` dans `.env` :
```bash
MAX_FILE_SIZE_BYTES=104857600  # 100 MB
```

### Chunking trop lent

**Solution** :
1. Activer le cache (d√©j√† activ√© par d√©faut)
2. R√©duire la taille des segments
3. R√©duire le nombre de documents

### R√©sultats RAG non pertinents

**Solution** :
1. Augmenter le seuil de similarit√© (0.20 - 0.30)
2. R√©duire Top-K (3-5)
3. D√©sactiver MMR pour favoriser la pertinence
4. V√©rifier que les documents contiennent bien l'information recherch√©e

---

Pour plus d'informations, consultez :
- [README.md](README.md) - Vue d'ensemble du projet
- [utils.py](utils.py) - Fonctions utilitaires
- [config.py](config.py) - Configuration centralis√©e
