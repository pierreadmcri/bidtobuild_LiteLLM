# ü§ñ AI Document Scanner

Une application **Streamlit** intelligente qui automatise l'analyse et la synth√®se de documents de build (BCO, RPO, PTC, BDC).

L'outil scanne un r√©pertoire local, identifie les fichiers pertinents gr√¢ce √† des motifs (Regex), s√©lectionne automatiquement la version la plus r√©cente en cas de doublon, et g√©n√®re une synth√®se structur√©e via un LLM (OpenAI / GPT-4).

![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-App-red.svg)
![OpenAI](https://img.shields.io/badge/Backend-OpenAI-orange.svg)

## üöÄ Fonctionnalit√©s

- **üìÇ Scan Intelligent :** Analyse automatique d'un dossier local.
- **üîç Filtrage Regex :** D√©tection automatique des types de documents (RPO, PTC, BCO, BDC).
- **‚úÇÔ∏è Smart Chunking :** D√©coupe intelligente des documents avec overlap pour pr√©server le contexte.
- **üîç Recherche Vectorielle RAG :** Embeddings + similarit√© cosinus pour trouver les passages pertinents.
- **üéØ MMR (Maximal Marginal Relevance) :** Diversification des r√©sultats pour √©viter la redondance.
- **üíæ Cache Multi-niveaux :** Streamlit + disque pour √©viter les recalculs co√ªteux.
- **‚ö° Traitement Parall√®le :** Embeddings calcul√©s en parall√®le avec `ThreadPoolExecutor`.
- **üìÑ Support Multi-formats :** Lecture native des fichiers `.pdf`, `.docx`, `.txt`, `.xlsx`, `.xlsm`.
- **üß† Synth√®se IA :** G√©n√©ration d'analyses contextuelles via OpenAI GPT-4.

### Am√©liorations de S√©curit√© & Performance
- **üõ°Ô∏è Validation des Chemins :** Protection contre path traversal attacks.
- **üìè Limite de Taille :** Fichiers volumineux rejet√©s automatiquement (configurable).
- **üîÑ Retry Logic :** Tentatives automatiques avec exponential backoff en cas d'√©chec API.
- **‚è±Ô∏è Rate Limiting :** Gestion intelligente des quotas API.
- **üìù Logging Structur√© :** Tra√ßabilit√© compl√®te avec niveaux configurables.
- **‚ö†Ô∏è Gestion d'Erreurs :** Messages d'erreur sp√©cifiques et informatifs.

## üõ†Ô∏è Pr√©requis technique

- **Python 3.11** (Recommand√©)
- Acc√®s √† une cl√© API OpenAI
- **Structure de dossiers requise :**
  - üìÅ **Documents/** : Dossier principal avec un sous-dossier par client (important)
  - üìÅ **Cache/** : Stockage de la base vectorielle
  - üìÅ **Prompts/** : Contient le fichier `rag_system_prompt.txt` (prompt de r√©daction pour l'output) 

## üì¶ Installation

1. **Se positionner via terminal a l'endroit ou sera cr√©√© le Projet**
2. **Cloner le projet**
   ```bash
   git clone [https://github.com/votre-user/votre-repo.git](https://github.com/votre-user/votre-repo.git)
   cd votre-repo
   ```

## ü§ñ Lancer l'app
- Installer **Python 3.11**
- Se positionner dans le repertoire via Terminal
- Cr√©er un environnement virtuel :
  - **Windows** : `py -3.11 -m venv .venv`
  - **Mac/Linux** : `python3.11 -m venv .venv`
- Activer l'environnement virtuel Window : **.venv\Scripts\Activate.ps1** Mac : **source .venv/bin/activate**
- Installer les lib **pip install -r requirements.txt**
- Cr√©er un fichier **`.env`** √† la racine avec au minimum votre cl√© API et, si besoin, le mod√®le voulu :
  ```bash
  # Configuration OpenAI
  OPENAI_API_KEY="votre_cle"
  OPENAI_API_BASE="https://api.votre-proxy-llm.com"

  # (Optionnel) Forcer un mod√®le sp√©cifique
  MODEL_NAME="openai/gpt-4.1-mini"
  EMBEDDING_MODEL_NAME="openai/text-embedding-3-small"
  ```
- Lancer l'app : **streamlit run rag_analysis.py**

## üóÇÔ∏è Structure du code

Le projet est organis√© de mani√®re modulaire pour faciliter la maintenance :

- **`rag_analysis.py`** : Application principale Streamlit avec RAG (Retrieval-Augmented Generation)
  - Interface utilisateur interactive
  - Traitement intelligent des documents avec chunking
  - Recherche vectorielle et g√©n√©ration de r√©ponses contextuelles

- **`config.py`** : Configuration centralis√©e
  - Param√®tres API OpenAI
  - Limites de s√©curit√©
  - Configuration RAG (chunking, retrieval, etc.)

- **`utils.py`** : Fonctions utilitaires r√©utilisables
  - Wrappers API avec retry et rate limiting
  - Validation et s√©curit√©
  - Extraction de texte (PDF, DOCX, Excel, OCR)

- **`prompts/`** : Prompts syst√®me externalis√©s et modifiables

- **`requirements.txt`** : D√©pendances Python (Streamlit, OpenAI, pandas, etc.)

### Flux de fonctionnement RAG

1. **Upload/Scan** : L'utilisateur s√©lectionne un dossier de documents
2. **Chunking** : Les documents sont d√©coup√©s en segments intelligents
3. **Embeddings** : Vectorisation des segments (cache disque pour performance)
4. **Prompts** : Le prompt de r√©daction est lu
5. **Retrieval** : Recherche des segments les plus pertinents par similarit√© cosinus
6. **Generation** : Le LLM g√©n√®re une r√©ponse bas√©e sur les segments r√©cup√©r√©s

## üìö Documentation Compl√®te

- **[CONFIGURATION.md](CONFIGURATION.md)** : Guide d√©taill√© de configuration
  - Variables d'environnement
  - Param√®tres RAG (chunking, retrieval)
  - Optimisation des performances
  - Estimation des co√ªts
  - Troubleshooting

- **[config.py](config.py)** : Configuration centralis√©e
- **[utils.py](utils.py)** : Fonctions utilitaires avec retry, validation, rate limiting
- **[prompts/](prompts/)** : Prompts syst√®me externalis√©s et modifiables

## üîí S√©curit√©

Le projet impl√©mente plusieurs mesures de s√©curit√© :

1. **Validation des chemins** : Protection contre path traversal
2. **Limite de taille** : Fichiers trop volumineux rejet√©s (50 MB par d√©faut)
3. **Rate limiting** : Pr√©vention du d√©passement de quotas API
4. **Logs s√©curis√©s** : Pas d'exposition des cl√©s API ou donn√©es sensibles
5. **Gestion d'erreurs robuste** : Messages informatifs sans r√©v√©ler d'informations syst√®me

## ‚ö° Performances

- **Traitement parall√®le** : Embeddings calcul√©s avec 4 workers simultan√©s
- **Cache intelligent** : R√©utilisation des embeddings pour les analyses r√©p√©t√©es
- **Scalabilit√©** : Id√©al pour corpus de 20+ documents
- **Temps initial** : ~60-90 secondes (cr√©ation des embeddings)
- **Temps avec cache** : ~5-10 secondes (r√©utilisation)

### Optimisations Recommand√©es

Pour documents volumineux (> 20 fichiers) :
```python
# config.py
NB_WORKERS = 6  # Augmenter les workers
BATCH_SIZE = 15  # Lots plus grands
```

Pour r√©seau instable :
```python
# config.py
MAX_RETRIES = 5  # Plus de tentatives
RETRY_MAX_DELAY = 32  # D√©lai max plus long
```
